{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665aa858-7742-4f4f-b5bf-03a762c5ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from pathlib import Path\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf4714b-f53f-4a64-9f1a-26cb515e1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calibration matrices from text files\n",
    "def load_calibration_matrices():\n",
    "    left_camera_matrix = np.loadtxt(\"left_camera_matrix.txt\")\n",
    "    right_camera_matrix = np.loadtxt(\"right_camera_matrix.txt\")\n",
    "    return left_camera_matrix, right_camera_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f91cc1-57ce-4dc3-8fc2-af7218ad095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract focal length from camera matrices\n",
    "def extract_focal_length(camera_matrix):\n",
    "    fx = camera_matrix[0, 0]\n",
    "    fy = camera_matrix[1, 1]\n",
    "    focal_length = (fx + fy) / 2\n",
    "    return focal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e210ff47-659b-465c-9cd8-a89ccb808b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up and start the DepthAI pipeline\n",
    "def setup_depthai_pipeline(left_camera_matrix, right_camera_matrix):\n",
    "    # Calculate focal lengths\n",
    "    focal_length_left = extract_focal_length(left_camera_matrix)\n",
    "    focal_length_right = extract_focal_length(right_camera_matrix)\n",
    "\n",
    "    # Baseline in millimeters\n",
    "    baseline_mm = 53.27\n",
    "\n",
    "    # Create DepthAI pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define mono cameras\n",
    "    mono_left = pipeline.createMonoCamera()\n",
    "    mono_right = pipeline.createMonoCamera()\n",
    "\n",
    "    # Connect mono cameras to stereo depth\n",
    "    stereo = pipeline.createStereoDepth()\n",
    "    mono_left.out.link(stereo.left)\n",
    "    mono_right.out.link(stereo.right)\n",
    "\n",
    "    # Set stereo depth properties\n",
    "    stereo.setBaseline(baseline_mm)\n",
    "    stereo.setFocalLength(focal_length_left)\n",
    "\n",
    "    # Create output streams for RGB and depth map\n",
    "    xout_rgb = pipeline.createXLinkOut()\n",
    "    xout_rgb.setStreamName(\"rgb\")\n",
    "    mono_left.out.link(xout_rgb.input)\n",
    "\n",
    "    xout_depth = pipeline.createXLinkOut()\n",
    "    xout_depth.setStreamName(\"depth\")\n",
    "    stereo.depth.link(xout_depth.input)\n",
    "\n",
    "    # Connect to the device and start the pipeline\n",
    "    with dai.Device(pipeline) as device:\n",
    "        # Output queues\n",
    "        rgb_queue = device.getOutputQueue(name=\"rgb\", maxSize=1, blocking=False)\n",
    "        depth_queue = device.getOutputQueue(name=\"depth\", maxSize=1, blocking=False)\n",
    "\n",
    "        while True:\n",
    "            # Retrieve RGB and depth frames from the output queues\n",
    "            rgb_frame = rgb_queue.get()\n",
    "            depth_frame = depth_queue.get()\n",
    "\n",
    "            if rgb_frame is not None and depth_frame is not None:\n",
    "                # Process RGB frame\n",
    "                rgb_img = rgb_frame.getCvFrame()\n",
    "                # Convert BGR to RGB for proper display\n",
    "                rgb_img = cv.cvtColor(rgb_img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "                # Process depth frame\n",
    "                depth_img = depth_frame.getFrame()\n",
    "                # Convert depth map to grayscale for visualization\n",
    "                depth_img = cv.cvtColor(depth_img, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "                # Display RGB and depth frames\n",
    "                cv.imshow(\"RGB\", rgb_img)\n",
    "                cv.imshow(\"Depth\", depth_img)\n",
    "                # Check for key press\n",
    "                key = cv.waitKey(1)\n",
    "                if key == ord(\"q\"):  # Close windows if 'q' is pressed\n",
    "                    cv.destroyAllWindows()\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60d9d8-4151-43ad-a6b4-55db1e28466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184430103153850F00] [0.1] [0.842] [MonoCamera(0)] [error] OV7251 only supports THE_480_P/THE_400_P resolutions, defaulting to THE_480_P\n",
      "[184430103153850F00] [0.1] [0.842] [MonoCamera(1)] [error] OV7251 only supports THE_480_P/THE_400_P resolutions, defaulting to THE_480_P\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load calibration matrices\n",
    "    left_camera_matrix, right_camera_matrix = load_calibration_matrices()\n",
    "\n",
    "    # Set up DepthAI pipeline with loaded calibration matrices\n",
    "    setup_depthai_pipeline(left_camera_matrix, right_camera_matrix)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2b7c6-fff6-4926-9da9-6e0b89824ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
