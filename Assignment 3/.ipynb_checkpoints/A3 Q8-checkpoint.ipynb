{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc72723-1082-49b3-a2cd-89ee57707315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose tracking method (1: with marker, 2: without marker):  2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'depthai.Pipeline' object has no attribute 'createYoloDetection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m     track_with_marker()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mtrack_without_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid choice. Choose either 1 or 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 74\u001b[0m, in \u001b[0;36mtrack_without_marker\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m cam_rgb\u001b[38;5;241m.\u001b[39msetPreviewSize(\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m)  \u001b[38;5;66;03m# Set preview size\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Add YOLO object detection node\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m yolo_model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateYoloDetection\u001b[49m()\n\u001b[1;32m     75\u001b[0m yolo_model\u001b[38;5;241m.\u001b[39msetConfidenceThreshold(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Set confidence threshold\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Link camera to YOLO object detection\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'depthai.Pipeline' object has no attribute 'createYoloDetection'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from depthai import Pipeline, Device\n",
    "\n",
    "# Function to detect AprilTags in the frame\n",
    "def detect_apriltags(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect AprilTags in the frame\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250))\n",
    "\n",
    "    return corners, ids\n",
    "\n",
    "# Function to capture video using DepthAI and track objects with markers (e.g., AprilTags)\n",
    "def track_with_marker():\n",
    "    # Define the DepthAI pipeline\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # Define the camera node\n",
    "    cam_rgb = pipeline.createColorCamera()\n",
    "    cam_rgb.setPreviewSize(300, 300)  # Set preview size\n",
    "\n",
    "    # Create output queue for the camera node\n",
    "    cam_out = pipeline.createXLinkOut()\n",
    "    cam_out.setStreamName(\"cam_out\")\n",
    "    cam_rgb.preview.link(cam_out.input)\n",
    "\n",
    "    try:\n",
    "        # Connect to DepthAI device\n",
    "        with Device(pipeline) as device:\n",
    "            # Start pipeline\n",
    "            device.startPipeline()\n",
    "\n",
    "            # Get the output queue\n",
    "            cam_queue = device.getOutputQueue(name=\"cam_out\", maxSize=1, blocking=False)\n",
    "\n",
    "            # Create a video window\n",
    "            cv2.namedWindow(\"AprilTag Tracking\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "            while True:\n",
    "                # Get the next frame from the output queue\n",
    "                frame = cam_queue.get().getCvFrame()\n",
    "\n",
    "                # Detect AprilTags in the frame\n",
    "                corners, ids = detect_apriltags(frame)\n",
    "\n",
    "                # Draw detected AprilTags on the frame\n",
    "                if ids is not None:\n",
    "                    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "                # Display the frame with AprilTag markers\n",
    "                cv2.imshow(\"AprilTag Tracking\", frame)\n",
    "\n",
    "                # Check for 'q' key press to exit the loop\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Function to capture video using DepthAI and track objects without markers\n",
    "def track_without_marker():\n",
    "    # Define the DepthAI pipeline\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # Define the camera node\n",
    "    cam_rgb = pipeline.createColorCamera()\n",
    "    cam_rgb.setPreviewSize(300, 300)  # Set preview size\n",
    "\n",
    "    # Add YOLO object detection node\n",
    "    yolo_model = pipeline.createYoloDetection()\n",
    "    yolo_model.setConfidenceThreshold(0.5)  # Set confidence threshold\n",
    "\n",
    "    # Link camera to YOLO object detection\n",
    "    cam_rgb.preview.link(yolo_model.input)\n",
    "\n",
    "    # Create output queue for the YOLO object detection node\n",
    "    yolo_out = pipeline.createXLinkOut()\n",
    "    yolo_out.setStreamName(\"yolo_out\")\n",
    "    yolo_model.out.link(yolo_out.input)\n",
    "\n",
    "    try:\n",
    "        # Connect to DepthAI device\n",
    "        with Device(pipeline) as device:\n",
    "            # Start pipeline\n",
    "            device.startPipeline()\n",
    "\n",
    "            # Get the output queue\n",
    "            yolo_queue = device.getOutputQueue(name=\"yolo_out\", maxSize=1, blocking=False)\n",
    "\n",
    "            # Create a video window\n",
    "            cv2.namedWindow(\"Object Tracking\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "            while True:\n",
    "                # Get the next frame from the output queue\n",
    "                frame = yolo_queue.get().getCvFrame()\n",
    "\n",
    "                # Display the frame with detected objects\n",
    "                cv2.imshow(\"Object Tracking\", frame)\n",
    "\n",
    "                # Check for 'q' key press to exit the loop\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Main function to choose between tracking with or without marker\n",
    "if __name__ == \"__main__\":\n",
    "    method = input(\"Choose tracking method (1: with marker, 2: without marker): \")\n",
    "\n",
    "    if method == \"1\":\n",
    "        track_with_marker()\n",
    "    elif method == \"2\":\n",
    "        track_without_marker()\n",
    "    else:\n",
    "        print(\"Invalid choice. Choose either 1 or 2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03886df9-e218-4538-b7b4-fdfbc6d989dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
